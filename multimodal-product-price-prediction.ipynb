{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13340319,"sourceType":"datasetVersion","datasetId":8459429},{"sourceId":13363231,"sourceType":"datasetVersion","datasetId":8476590}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tqdm\n!pip install requests\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport requests\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom io import BytesIO\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# path to your CSV\ncsv_path = \"/kaggle/input/mlhack/train.csv\"\ncsv_path2=\"/kaggle/input/mlhack/test.csv\"\n# read CSV\ndf_train = pd.read_csv(csv_path)\ndf_test = pd.read_csv(csv_path2)\n\nprint(df_train.shape)\nprint(df_test.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**DOWNLOAD TRAIN IMAGES**","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport requests\nfrom tqdm import tqdm\nfrom multiprocessing import Pool, cpu_count\nfrom functools import partial\nfrom pathlib import Path\nimport time\n\n# ============== CONFIG ======================\ntrain_csv_path = \"/kaggle/input/mlhack/train.csv\"\ntrain_image_folder = \"/kaggle/working/train_images\"\nIMAGE_COLUMN = \"image_link\"\nMAX_WORKERS = min(64, cpu_count())  # Adjust concurrency\n# ============================================\n\n# Create directories\nos.makedirs(train_image_folder, exist_ok=True)\n\n# Load CSVs\ntrain_df = pd.read_csv(train_csv_path)\n\nprint(\"âœ… Columns in train:\", train_df.columns.tolist())\n\n# Extract image links\ntrain_links = train_df[IMAGE_COLUMN].dropna().unique().tolist()\n\nprint(f\"Train images to download: {len(train_links)}\")\n\n\n# ======================================================\n# ðŸ§© Function to download a single image robustly\n# ======================================================\ndef download_image(image_url, save_folder):\n    try:\n        filename = Path(image_url).name\n        save_path = os.path.join(save_folder, filename)\n\n        # Skip if already downloaded\n        if os.path.exists(save_path):\n            return \"exists\"\n\n        headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Prevent blocking\n        response = requests.get(image_url, headers=headers, timeout=10)\n\n        if response.status_code == 200:\n            with open(save_path, \"wb\") as f:\n                f.write(response.content)\n            return \"ok\"\n        else:\n            return f\"error_{response.status_code}\"\n\n    except Exception as e:\n        return f\"fail_{str(e)[:40]}\"\n\n\n# ======================================================\n# ðŸ§  Parallel Downloader\n# ======================================================\ndef parallel_download(image_links, folder):\n    print(f\"ðŸ“¥ Starting downloads â†’ {folder}\")\n    start = time.time()\n    os.makedirs(folder, exist_ok=True)\n    \n    download_fn = partial(download_image, save_folder=folder)\n    \n    results = []\n    with Pool(MAX_WORKERS) as pool:\n        for result in tqdm(pool.imap_unordered(download_fn, image_links), total=len(image_links)):\n            results.append(result)\n    \n    ok = sum(1 for r in results if r == \"ok\" or r == \"exists\")\n    fail = len(results) - ok\n    print(f\"âœ… Completed: {ok} | âš ï¸ Failed: {fail} | â±ï¸ Time: {round(time.time() - start, 2)}s\")\n    return ok, fail\n\n\n# ======================================================\n# ðŸš€ Run Train + Test Downloads\n# ======================================================\nok_train, fail_train = parallel_download(train_links, train_image_folder)\n\nprint(\"\\nðŸ“Š FINAL STATS:\")\nprint(f\"Train â†’ Downloaded: {ok_train}, Failed: {fail_train}\")\n\n# Optional sanity check\nprint(f\"\\nðŸ–¼ï¸ Train images in folder: {len(os.listdir(train_image_folder))}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**TEXT EMBEDDINGS AND FEATRUE ENGINEERING**","metadata":{}},{"cell_type":"code","source":"# Install required libs (run once)\n!pip install -q transformers datasets sentencepiece","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q --upgrade pip\n!pip install -q transformers accelerate torch torchvision --no-cache-dir","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*mapping downloaded train images ti thier coressponding text(catalog_content) and url*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Load your dataset\ntrain_df = pd.read_csv(\"/kaggle/input/mlhack/train.csv\")\n\n# Extract only the useful columns\ntrain_df = train_df[[\"image_link\", \"catalog_content\"]]\n\n# Derive image filenames from URLs (if needed)\ntrain_df[\"image_name\"] = train_df[\"image_link\"].apply(lambda x: os.path.basename(x))\n\n# Keep only rows where the image actually exists\nimage_folder = \"/kaggle/working/train_images\"\ntrain_df[\"exists\"] = train_df[\"image_name\"].apply(lambda x: os.path.exists(os.path.join(image_folder, x)))\ntrain_df = train_df[train_df[\"exists\"] == True].reset_index(drop=True)\n\nprint(\"âœ… Final usable samples:\", len(train_df))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**->FEATURE ENGINEERING**","metadata":{}},{"cell_type":"code","source":"\ntrain_csv_path= \"/kaggle/input/mlhack/train.csv\"\ntest_csv_path = \"/kaggle/input/mlhack/test.csv\"\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport pandas as pd\n\ndef extract_weight(text):\n    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(g|kg|oz|lb|ml|l)', text, re.IGNORECASE)\n    if match:\n        value, unit = match.groups()\n        value = float(value)\n        unit = unit.lower()\n        if unit == 'kg': value *= 1000\n        elif unit == 'lb': value *= 453.592\n        elif unit == 'oz': value *= 28.3495\n        elif unit == 'l': value *= 1000  # ml\n        return value\n    return 0\ntrain_df['weight_g'] = train_df['catalog_content'].apply(extract_weight)\n\ntest_df['weight_g'] = test_df['catalog_content'].apply(extract_weight)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_pack_count(text):\n    match = re.search(r'(\\d+)\\s*(?:x|X|pack of)\\s*\\d*', text, re.IGNORECASE)\n    if match:\n        return int(match.group(1))\n    return 1\n\ntrain_df['pack_count'] = train_df['catalog_content'].apply(extract_pack_count)\ntest_df['pack_count'] = test_df['catalog_content'].apply(extract_pack_count)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ntrain_df['num_tokens'] = train_df['catalog_content'].str.split().str.len()\ntrain_df['num_digits'] = train_df['catalog_content'].str.count(r'\\d')\ntrain_df['num_uppercase_words'] = train_df['catalog_content'].str.count(r'\\b[A-Z]{2,}\\b')\n\ntest_df['num_tokens'] = test_df['catalog_content'].str.split().str.len()\ntest_df['num_digits'] = test_df['catalog_content'].str.count(r'\\d')\ntest_df['num_uppercase_words'] = test_df['catalog_content'].str.count(r'\\b[A-Z]{2,}\\b')\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------\n# Utility preprocessing functions\n# -------------------------\ndef light_clean(text):\n    \"\"\"Minimal cleaning for DistilBERT: remove HTML, collapse whitespace, keep punctuation.\"\"\"\n    if text is None:\n        return \"\"\n    text = str(text)\n    # remove html tags\n    text = re.sub(r'<[^>]+>', ' ', text)\n    # replace newlines / tabs with space\n    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n    # collapse multi-spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# Example regex extraction for weight/quantity (optional but high ROI)\ndef extract_quantity_and_weight(text):\n    \"\"\"\n    Returns tuple (quantity_int_or_nan, weight_grams_or_nan)\n    This is a heuristic extractor â€” tweak regexes for your data.\n    \"\"\"\n    q = np.nan\n    w = np.nan\n    if not text:\n        return q, w\n    # pack counts like 'pack of 6', '6 pack', '6 x 250g'\n    m = re.search(r'(\\bpack of\\b|\\bpack\\b|\\bx\\b)\\s*(\\d{1,3})', text, flags=re.I)\n    if m:\n        try:\n            q = int(re.search(r'(\\d{1,3})', m.group(0)).group(1))\n        except:\n            q = np.nan\n    # weights like '250 g', '250g', '0.5 kg', '12 oz'\n    m2 = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(kg|g|gram|grams|oz|ounce|ounces|ml|l|litre|liter)\\b', text, flags=re.I)\n    if m2:\n        val = float(m2.group(1))\n        unit = m2.group(2).lower()\n        # convert to grams/ml where possible\n        if unit in ['kg']:\n            w = val * 1000.0\n        elif unit in ['g','gram','grams']:\n            w = val\n        elif unit in ['mg']:\n            w = val / 1000.0\n        elif unit in ['l','litre','liter']:\n            w = val * 1000.0  # liters -> ml (approx)\n        elif unit in ['ml']:\n            w = val\n        elif unit in ['oz','ounce','ounces']:\n            w = val * 28.3495\n    return q, w\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------\n# Load dataset(s)\n# -------------------------\nprint(\"Loading CSVs...\")\ntrain_df = pd.read_csv(TRAIN_CSV)\nprint(\"Train rows:\", len(train_df))\nif os.path.exists(TEST_CSV):\n    test_df = pd.read_csv(TEST_CSV)\n    print(\"Test rows:\", len(test_df))\nelse:\n    test_df = None\nprint(\"Using text column:\", TEXT_COL)\n\n# Fill missing and clean text\ntrain_df[TEXT_COL] = train_df[TEXT_COL].fillna(\"\").astype(str).apply(light_clean)\nif test_df is not None:\n    test_df[TEXT_COL] = test_df[TEXT_COL].fillna(\"\").astype(str).apply(light_clean)\n\n# Optional: extract numeric structured features from the text (quantity, weight)\nprint(\"Extracting quantity/weight heuristics (optional)...\")\ntrain_qw = train_df[TEXT_COL].apply(extract_quantity_and_weight)\ntrain_df['qty'] = [x[0] for x in train_qw]\ntrain_df['weight_g'] = [x[1] for x in train_qw]\n\nif test_df is not None:\n    test_qw = test_df[TEXT_COL].apply(extract_quantity_and_weight)\n    test_df['qty'] = [x[0] for x in test_qw]\n    test_df['weight_g'] = [x[1] for x in test_qw]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*->TEST EMBEDDINGS AND FEATURE EMBEDDINGS OF TEST SET*","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\n\n# ===============================\n# Config\n# ===============================\nTEXT_COL = \"catalog_content\"\nBATCH_SIZE = 64\nMAX_LEN = 128\nMODEL_NAME = \"distilbert-base-uncased\"\nOUTPUT_DIR = \"/kaggle/working/test_embeddings_features\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nTEST_CSV = \"/kaggle/input/mlhack/test.csv\"\n\n# ===============================\n# Load test dataset\n# ===============================\ntest_df = pd.read_csv(TEST_CSV)\n\n# Clean text\ndef light_clean(text):\n    if text is None:\n        return \"\"\n    text = str(text)\n    text = re.sub(r'<[^>]+>', ' ', text)\n    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ntest_df[TEXT_COL] = test_df[TEXT_COL].fillna(\"\").astype(str).apply(light_clean)\n\n# ===============================\n# Device and model setup\n# ===============================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModel.from_pretrained(MODEL_NAME).to(device)\nmodel.eval()\n\n# -------------------------------\n# Mean pooling\ndef mean_pooling(token_embeddings, attention_mask):\n    mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeds = torch.sum(token_embeddings * mask_expanded, 1)\n    sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n    return sum_embeds / sum_mask\n\n# -------------------------------\n# Encode test texts to embeddings\ndef encode_texts_to_embeddings(df, text_col, out_path, batch_size=BATCH_SIZE, max_length=MAX_LEN):\n    n = len(df)\n    emb_dim = model.config.hidden_size\n    embeddings = np.zeros((n, emb_dim), dtype=np.float32)\n\n    texts = df[text_col].fillna(\"\").astype(str).tolist()\n    with torch.no_grad():\n        for start in tqdm(range(0, n, batch_size), desc=f\"Encoding {os.path.basename(out_path)}\"):\n            end = min(n, start + batch_size)\n            batch_texts = texts[start:end]\n            encoded = tokenizer(batch_texts, padding=True, truncation=True,\n                                max_length=max_length, return_tensors='pt')\n            input_ids = encoded['input_ids'].to(device)\n            attention_mask = encoded['attention_mask'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            pooled = mean_pooling(outputs.last_hidden_state, attention_mask).cpu().numpy()\n            embeddings[start:end, :] = pooled\n\n    embeddings = np.nan_to_num(embeddings, nan=0.0)\n    np.save(out_path, embeddings)\n    print(f\"Saved test text embeddings: {out_path}\")\n    return embeddings\n\n# -------------------------------\n# Save engineered numeric/categorical features for test\ndef save_engineered_features(df, out_path, text_col=TEXT_COL):\n    exclude_cols = [text_col, 'sample_id']\n    numeric_df = df[[c for c in df.columns if c not in exclude_cols]].copy()\n\n    for col in numeric_df.select_dtypes(include='object').columns:\n        numeric_df[col] = numeric_df[col].fillna(\"nan_missing\")\n        le = LabelEncoder()\n        numeric_df[col] = le.fit_transform(numeric_df[col].astype(str))\n\n    numeric_df = numeric_df.fillna(0)\n    np.save(out_path, numeric_df.values.astype(np.float32))\n    print(f\"Saved test engineered numeric features: {out_path}\")\n    return numeric_df.values\n\n# ===============================\n# Paths for saving test embeddings/features\ntest_text_emb_path = os.path.join(OUTPUT_DIR, \"test_catalog_text_emb.npy\")\ntest_features_path = os.path.join(OUTPUT_DIR, \"test_engineered_numeric_features.npy\")\n\n# ===============================\n# Process test set\ntest_text_emb = encode_texts_to_embeddings(test_df, TEXT_COL, test_text_emb_path)\ntest_features = save_engineered_features(test_df, test_features_path, text_col=TEXT_COL)\n\nprint(\"âœ… Test embeddings and features saved.\")\nprint(\"Test text embeddings:\", test_text_emb_path)\nprint(\"Test engineered numeric features:\", test_features_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*->TRAIN EMBEDDINGS AND FEATURE ENGG EMBEDDINGS OF TRAIN SET*","metadata":{}},{"cell_type":"code","source":"# ===============================\n# DistilBERT embeddings + Engineered numeric features (NaN-safe) for train/test\n# ===============================\nimport os\nimport re\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\n\n# ===============================\n# Config\n# ===============================\nTEXT_COL = \"catalog_content\"  # Text column\nBATCH_SIZE = 64\nMAX_LEN = 128\nMODEL_NAME = \"distilbert-base-uncased\"\nOUTPUT_DIR = \"/kaggle/working/embeddings_features\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# CSV paths\nTRAIN_CSV = \"/kaggle/input/mlhack/train.csv\"\nTEST_CSV = \"/kaggle/input/mlhack/test.csv\"\n\n# ===============================\n# Load datasets\n# ===============================\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\n\n# Fill missing text with empty string and clean\ndef light_clean(text):\n    if text is None:\n        return \"\"\n    text = str(text)\n    text = re.sub(r'<[^>]+>', ' ', text)\n    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ntrain_df[TEXT_COL] = train_df[TEXT_COL].fillna(\"\").astype(str).apply(light_clean)\ntest_df[TEXT_COL] = test_df[TEXT_COL].fillna(\"\").astype(str).apply(light_clean)\n\n# ===============================\n# Device and model setup\n# ===============================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModel.from_pretrained(MODEL_NAME).to(device)\nmodel.eval()\n\n# -------------------------------\n# Mean pooling\ndef mean_pooling(token_embeddings, attention_mask):\n    mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeds = torch.sum(token_embeddings * mask_expanded, 1)\n    sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n    return sum_embeds / sum_mask\n\n# -------------------------------\n# Encode text to embeddings\ndef encode_texts_to_embeddings(df, text_col, out_path, batch_size=BATCH_SIZE, max_length=MAX_LEN):\n    n = len(df)\n    emb_dim = model.config.hidden_size\n    embeddings = np.zeros((n, emb_dim), dtype=np.float32)\n\n    texts = df[text_col].fillna(\"\").astype(str).tolist()\n    with torch.no_grad():\n        for start in tqdm(range(0, n, batch_size), desc=f\"Encoding {os.path.basename(out_path)}\"):\n            end = min(n, start + batch_size)\n            batch_texts = texts[start:end]\n            encoded = tokenizer(batch_texts, padding=True, truncation=True,\n                                max_length=max_length, return_tensors='pt')\n            input_ids = encoded['input_ids'].to(device)\n            attention_mask = encoded['attention_mask'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            pooled = mean_pooling(outputs.last_hidden_state, attention_mask).cpu().numpy()\n            embeddings[start:end, :] = pooled\n\n    # Replace any NaNs (just in case)\n    embeddings = np.nan_to_num(embeddings, nan=0.0)\n    np.save(out_path, embeddings)\n    print(f\"Saved text embeddings: {out_path}\")\n    return embeddings\n\n# -------------------------------\n# Save engineered numeric/categorical features\ndef save_engineered_features(df, out_path, text_col=TEXT_COL, target_col=None, train_le_dict=None):\n    # Exclude text and optionally target\n    exclude_cols = [text_col, 'sample_id']\n    if target_col is not None and target_col in df.columns:\n        exclude_cols.append(target_col)\n\n    engineered_cols = [c for c in df.columns if c not in exclude_cols]\n    numeric_df = df[engineered_cols].copy()\n\n    le_dict = {} if train_le_dict is None else train_le_dict\n\n    for col in numeric_df.select_dtypes(include='object').columns:\n        if train_le_dict is None:  # train set\n            le = LabelEncoder()\n            numeric_df[col] = numeric_df[col].fillna(\"nan_missing\")\n            numeric_df[col] = le.fit_transform(numeric_df[col].astype(str))\n            le_dict[col] = le\n        else:  # test set\n            le = le_dict[col]\n            numeric_df[col] = numeric_df[col].fillna(\"nan_missing\")\n            numeric_df[col] = numeric_df[col].apply(lambda x: x if x in le.classes_ else \"nan_missing\")\n            numeric_df[col] = le.transform(numeric_df[col].astype(str))\n\n    # Fill numeric NaNs with 0\n    numeric_df = numeric_df.fillna(0)\n\n    np.save(out_path, numeric_df.values.astype(np.float32))\n    print(f\"Saved engineered numeric features: {out_path}\")\n    return numeric_df.values, le_dict\n\n# ===============================\n# Paths for saving\ntrain_text_emb_path = os.path.join(OUTPUT_DIR, \"train_catalog_text_emb.npy\")\ntrain_features_path = os.path.join(OUTPUT_DIR, \"train_engineered_numeric_features.npy\")\ntest_text_emb_path = os.path.join(OUTPUT_DIR, \"test_catalog_text_emb.npy\")\ntest_features_path = os.path.join(OUTPUT_DIR, \"test_engineered_numeric_features.npy\")\n\n# ===============================\n# Process train\ntrain_text_emb = encode_texts_to_embeddings(train_df, TEXT_COL, train_text_emb_path)\ntrain_features, le_dict = save_engineered_features(train_df, train_features_path, text_col=TEXT_COL, target_col='price')\n\n# ===============================\n# Process test (no target column in test)\ntest_text_emb = encode_texts_to_embeddings(test_df, TEXT_COL, test_text_emb_path)\ntest_features, _ = save_engineered_features(test_df, test_features_path, text_col=TEXT_COL, target_col=None, train_le_dict=le_dict)\n\n# ===============================\nprint(\"âœ… All embeddings and features saved separately for train and test.\")\nprint(\"Train text embeddings:\", train_text_emb_path)\nprint(\"Train engineered numeric features:\", train_features_path)\nprint(\"Test text embeddings:\", test_text_emb_path)\nprint(\"Test engineered numeric features:\", test_features_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**LOADING TEXT EMBED, FEATURE EMBED AND IMAGE EMBEDS OF TRAIN AND TEST**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Load your train dataframe and embeddings\ntrain_df = pd.read_csv(\"/kaggle/input/mlhack/train.csv\")\ntrain_text_embeds = np.load(\"/kaggle/input/embeddings/train_catalog_text_emb.npy\")\nimage_embeds = np.load(\"/kaggle/input/embeddings/image_embeddings.npy\")\ntest_fe_embd=np.load(\"/kaggle/input/embeddings/train_engineered_numeric_features (1).npy\")\nprint(\"Text embeddings:\", train_text_embeds.shape)\nprint(\"Image embeddings:\", image_embeds.shape)\ntest_fe_embd.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*fill missing image embed vector with a similar embed image vector from train_image_embed*","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Your arrays\ntext_embeds = train_text_embeds\nimg_embeds = image_embeds\nnum_feat = test_fe_embd\n\n# Check and fix\nif img_embeds.shape[0] < text_embeds.shape[0]:\n    missing_rows = text_embeds.shape[0] - img_embeds.shape[0]\n    print(f\"âš ï¸ Missing {missing_rows} image embedding row(s). Fixing using mean vector...\")\n\n    # Compute mean image embedding vector\n    mean_vector = np.mean(img_embeds, axis=0, keepdims=True)\n\n    # Append missing rows (duplicate mean_vector)\n    img_embeds_fixed = np.vstack([img_embeds, np.repeat(mean_vector, missing_rows, axis=0)])\nelse:\n    img_embeds_fixed = img_embeds\n\nprint(\"âœ… Fixed image embedding shape:\", img_embeds_fixed.shape)\n\n# Sanity check\nassert text_embeds.shape[0] == img_embeds_fixed.shape[0] == num_feat.shape[0]\nprint(\"âœ… All arrays aligned:\", text_embeds.shape, img_embeds_fixed.shape, num_feat.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_embeds_fixed.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Load your train dataframe and embeddings\ntest_df = pd.read_csv(\"/kaggle/input/mlhack/test.csv\")\ntest_text_embeds = np.load(\"/kaggle/input/embeddings/test_catalog_text_emb (2).npy\")\nimage_embeds_test = np.load(\"/kaggle/working/image_test_embeddings.npy\")\ntest_feat_embd=np.load(\"/kaggle/input/embeddings/test_engineered_numeric_features (1).npy\")\nprint(\"Text embeddings:\", test_text_embeds.shape)\nprint(\"Image embeddings:\", image_embeds_test.shape)\ntest_feat_embd.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*fill missing image embed vector with a similar embed image vector from test_image_embed*","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Your arrays\ntext_embeds_test = test_text_embeds\nimg_embeds_test = image_embeds_test\nnum_feat_test= test_feat_embd\n\n# Check and fix\nif img_embeds.shape[0] < text_embeds.shape[0]:\n    missing_rows = text_embeds.shape[0] - img_embeds.shape[0]\n    print(f\"âš ï¸ Missing {missing_rows} image embedding row(s). Fixing using mean vector...\")\n\n    # Compute mean image embedding vector\n    mean_vector = np.mean(img_embeds, axis=0, keepdims=True)\n\n    # Append missing rows (duplicate mean_vector)\n    img_embeds_fixed_test = np.vstack([img_embeds, np.repeat(mean_vector, missing_rows, axis=0)])\nelse:\n    img_embeds_fixed_test= img_embeds\n\nprint(\"âœ… Fixed image embedding shape:\", img_embeds_fixed_test.shape)\n\n# Sanity check\nassert text_embeds.shape[0] == img_embeds_fixed_test.shape[0] == num_feat.shape[0]\nprint(\"âœ… All arrays aligned:\", text_embeds_test.shape, img_embeds_fixed_test.shape, num_feat_test.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_feat_embd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.isnan(test_feat_embd).any(), np.isnan(test_feat_embd).sum()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------\n# Concatenate all TRAIN features\n# -------------------------\nX_train_full = np.concatenate([text_embeds, img_embeds_fixed, num_feat], axis=1)\n\nprint(\"Final train shape:\", X_train_full.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------\n# Concatenate all TEST features\n# -------------------------\nX_test_full = np.concatenate([text_embeds_test,  img_embeds_fixed_test , num_feat_test], axis=1)\n\nprint(\"Final train shape:\", X_test_full.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.isnan(X_train_full).any(), np.isnan(X_train_full).sum()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\ntrain_df = pd.read_csv(\"/kaggle/input/mlhack/train.csv\")\n\n# Apply log1p (i.e., log(1 + x)) to avoid log(0)\ny = np.log1p(train_df[\"price\"].values)\n\nprint(\"Before log transform:\", train_df[\"price\"].describe())\nprint(\"\\nAfter log transform:\", pd.Series(y).describe())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# -------------------------\n# Train/validation split\n# -------------------------\nX_train_split, X_valide, y_train_split, y_valide = train_test_split(\n    X_train_full, y, test_size=0.2, random_state=42\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_split.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# y_true and y_pred are original scale values\ndef smape(y_true, y_pred):\n    return 100 * np.mean(np.abs(y_pred - y_true) / ((np.abs(y_true) + np.abs(y_pred)) / 2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**TRAIN SET IMAGE EMBEDDINGS USING RESNET**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, df, image_folder, transform):\n        self.df = df\n        self.image_folder = image_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = self.df.iloc[idx][\"image_name\"]\n        img_path = os.path.join(self.image_folder, img_name)\n\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n            image = self.transform(image)\n        except Exception as e:\n            # fallback: black image if something fails\n            image = torch.zeros(3, 224, 224)\n\n        return image\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resnet = models.resnet50(pretrained=True)\nresnet = nn.Sequential(*list(resnet.children())[:-1])  # remove final layer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet = resnet.to(device)\nresnet.eval()\n\nprint(\"âœ… Using device:\", device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_folder = \"/kaggle/working/train_images\"\n\ndataset = ImageDataset(train_df, image_folder, image_transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_features = []\n\nwith torch.no_grad():\n    for batch in tqdm(dataloader, desc=\"Extracting image embeddings (batched)\"):\n        batch = batch.to(device)\n        features = resnet(batch)                      # shape: [B, 2048, 1, 1]\n        features = features.view(features.size(0), -1)  # shape: [B, 2048]\n        all_features.append(features.cpu().numpy())\n\n# Combine all batches\nimage_embeddings = np.concatenate(all_features, axis=0)\nprint(\"âœ… Image embeddings shape:\", image_embeddings.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save(\"/kaggle/working/image_embeddings.npy\", image_embeddings)\nprint(\"âœ… Saved image embeddings successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**TEST IMAGE DOWNLOAD AND CREATE TEST IMAGE EMBEDS USING RESNET**","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport requests\nfrom tqdm import tqdm\nfrom multiprocessing import Pool, cpu_count\nfrom functools import partial\nfrom pathlib import Path\nimport time\n\n# ============== CONFIG ======================\ntrain_csv_path = \"/kaggle/input/mlhack/test.csv\"\ntrain_image_folder = \"/kaggle/working/test_images\"\nIMAGE_COLUMN = \"image_link\"\nMAX_WORKERS = min(64, cpu_count())  # Adjust concurrency\n# ============================================\n\n# Create directories\nos.makedirs(train_image_folder, exist_ok=True)\n\n# Load CSVs\ntrain_df = pd.read_csv(train_csv_path)\n\nprint(\"âœ… Columns in train:\", train_df.columns.tolist())\n\n# Extract image links\ntrain_links = train_df[IMAGE_COLUMN].dropna().unique().tolist()\n\nprint(f\"Train images to download: {len(train_links)}\")\n\n\n# ======================================================\n# ðŸ§© Function to download a single image robustly\n# ======================================================\ndef download_image(image_url, save_folder):\n    try:\n        filename = Path(image_url).name\n        save_path = os.path.join(save_folder, filename)\n\n        # Skip if already downloaded\n        if os.path.exists(save_path):\n            return \"exists\"\n\n        headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Prevent blocking\n        response = requests.get(image_url, headers=headers, timeout=10)\n\n        if response.status_code == 200:\n            with open(save_path, \"wb\") as f:\n                f.write(response.content)\n            return \"ok\"\n        else:\n            return f\"error_{response.status_code}\"\n\n    except Exception as e:\n        return f\"fail_{str(e)[:40]}\"\n\n\n# ======================================================\n# ðŸ§  Parallel Downloader\n# ======================================================\ndef parallel_download(image_links, folder):\n    print(f\"ðŸ“¥ Starting downloads â†’ {folder}\")\n    start = time.time()\n    os.makedirs(folder, exist_ok=True)\n    \n    download_fn = partial(download_image, save_folder=folder)\n    \n    results = []\n    with Pool(MAX_WORKERS) as pool:\n        for result in tqdm(pool.imap_unordered(download_fn, image_links), total=len(image_links)):\n            results.append(result)\n    \n    ok = sum(1 for r in results if r == \"ok\" or r == \"exists\")\n    fail = len(results) - ok\n    print(f\"âœ… Completed: {ok} | âš ï¸ Failed: {fail} | â±ï¸ Time: {round(time.time() - start, 2)}s\")\n    return ok, fail\n\n\n# ======================================================\n# ðŸš€ Run Train + Test Downloads\n# ======================================================\nok_train, fail_train = parallel_download(train_links, train_image_folder)\n\nprint(\"\\nðŸ“Š FINAL STATS:\")\nprint(f\"Train â†’ Downloaded: {ok_train}, Failed: {fail_train}\")\n\n# Optional sanity check\nprint(f\"\\nðŸ–¼ï¸ Train images in folder: {len(os.listdir(train_image_folder))}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*MAP DOWNLOADED IMAGES TO ITS CORESSPONDING TEXT AND URL*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Load your dataset\ntrain_df = pd.read_csv(\"/kaggle/input/mlhack/test.csv\")\n\n# Extract only the useful columns\ntrain_df = train_df[[\"image_link\", \"catalog_content\"]]\n\n# Derive image filenames from URLs (if needed)\ntrain_df[\"image_name\"] = train_df[\"image_link\"].apply(lambda x: os.path.basename(x))\n\n# Keep only rows where the image actually exists\nimage_folder = \"/kaggle/working/test_images\"\ntrain_df[\"exists\"] = train_df[\"image_name\"].apply(lambda x: os.path.exists(os.path.join(image_folder, x)))\ntrain_df = train_df[train_df[\"exists\"] == True].reset_index(drop=True)\nprint(\"âœ… Final usable samples:\", len(train_df))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\n\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, df, image_folder, transform):\n        self.df = df\n        self.image_folder = image_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = self.df.iloc[idx][\"image_name\"]\n        img_path = os.path.join(self.image_folder, img_name)\n\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n            image = self.transform(image)\n        except Exception as e:\n            # fallback: black image if something fails\n            image = torch.zeros(3, 224, 224)\n\n        return image\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resnet = models.resnet50(pretrained=True)\nresnet = nn.Sequential(*list(resnet.children())[:-1])  # remove final layer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet = resnet.to(device)\nresnet.eval()\n\nprint(\"âœ… Using device:\", device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_folder = \"/kaggle/working/test_images\"\n\ndataset = ImageDataset(train_df, image_folder, image_transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_features = []\n\nwith torch.no_grad():\n    for batch in tqdm(dataloader, desc=\"Extracting image embeddings (batched)\"):\n        batch = batch.to(device)\n        features = resnet(batch)                      # shape: [B, 2048, 1, 1]\n        features = features.view(features.size(0), -1)  # shape: [B, 2048]\n        all_features.append(features.cpu().numpy())\n\n# Combine all batches\nimage_embeddings = np.concatenate(all_features, axis=0)\nprint(\"âœ… Image embeddings shape:\", image_embeddings.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save(\"/kaggle/working/image_test_embeddings.npy\", image_embeddings)\nprint(\"âœ… Saved image embeddings successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\nstart = time.time()\nfrom xgboost import XGBRegressor\n\nmodel = XGBRegressor(\n    tree_method=\"gpu_hist\",\n    predictor=\"gpu_predictor\",\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=8,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    objective=\"reg:squarederror\",  # âœ… regression objective\n    eval_metric=\"rmse\"              # âœ… root mean square error\n)\n\n\nmodel.fit(X_train_split, y_train_split, verbose=True)\nprint(\"âœ… Model trained in\", round(time.time() - start, 2), \"seconds\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport numpy as np\n\ny_pred = model.predict(X_valide)\n\nmse = mean_squared_error(y_valide, y_pred)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(y_valide, y_pred)\nr2 = r2_score(y_valide, y_pred)\nsmape_score = smape(y_valide, y_pred)\n\nprint(\"SMAPE:\", smape_score, \"%\")\nprint(\"MSE:\", mse)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)\nprint(\"R2 Score:\", r2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load test CSV\nTEST_CSV = \"/kaggle/input/mlhack/test.csv\"\ntest_df = pd.read_csv(TEST_CSV)\n\n# Predict with both models\nxgb_test_preds = xgb_model.predict(X_test_full)\nmlp_test_preds = mlp_model(torch.tensor(X_test_full, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n\n# Ensemble\nfinal_test_preds = 0.6 * xgb_test_preds + 0.4 * mlp_test_preds\n\n# Convert back from log\nfinal_test_preds_exp = np.expm1(final_test_preds)\n\n# Create submission DataFrame\nsubmission_df = pd.DataFrame({\n    \"sample_id\": test_df[\"sample_id\"].iloc[:X_test_full.shape[0]],  # align sample_id with available rows\n    \"price\": final_test_preds_exp.flatten()\n})\n\n# Save CSV\nsubmission_df.to_csv(\"/kaggle/working/XGBoost_mlp_predictions.csv\", index=False)\nprint(\"âœ… Predictions saved to tabnet_test_predictions.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}